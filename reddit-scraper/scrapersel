#Selenium Variation
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait 
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

import time
#data-testid="post-container"
#data-adclicklocation="title"
#data-click-id="body"
#--posttitletextcolor: #373c3f;


#website being scraped
url = "https://www.reddit.com/r/wallstreetbets/"
# initialize a web driver to control Chrome
driver = webdriver.Chrome()
# scraping logic...
driver.get(url)
time.sleep(5)
posts = driver.find_element(By.ID, "2x-container")
print(posts)
#WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'subredditvars-r-wallstreetbets')))
#title = locate_with(By.TAG_NAME, 'H3').below(By.TAG_NAME, 'H2')
driver.execute_script(f"window.scrollBy(0, {2500});")
time.sleep(1)
soup = BeautifulSoup(driver.page_source, 'lxml')
#articles = soup.findall('h3')


#while(postcount<10):
#    post_html_elements = driver.find_elements(By.CLASS_NAME, 'SQnoC3ObvgnGjWt90zD9Z _2INHSNB8V5eaWp4P0rY_mE')
#    for post_html_element in post_html_elements:
#        upvotes = post_html_element.find_element(By.CSS_SELECTOR, '[data-click-id="upvote"]').find_element(By.XPATH, "following-sibling::*[1]").get_attribute('innerText')
#        title = post_html_element.find_element(By.TAG_NAME, 'h3').text
#        post = {}
#        post['title'] = title
#        post['upvotes'] = upvotes
#        posts.append(post)
#    postcount+=1
# close the browser and free up the Selenium resources


driver.quit()
print(posts)
