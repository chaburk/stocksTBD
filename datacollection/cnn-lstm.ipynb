{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d736d624-6085-4243-8920-477e7f86922b",
   "metadata": {},
   "source": [
    "Machine Learning Model: Convolutional NN - LSTM model\n",
    "The code is a CNN-LSTM model for stock price prediction that takes as input the cleaned stock data.\n",
    "Some conversions are made to the date, as well as the addition of new variables before the model is created.\n",
    "Name: Sean Brady\n",
    "Created: Dec 3, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32b262b-29be-4c15-8a9c-34cc8f2be40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#must use anaconda enviornment to import tensorflow modules\n",
    "#at least on my computer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c402b81-9c48-4643-92a4-d58592ccc658",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   open    high     low  close    volume   7_day_ma  15_day_ma  \\\n",
      "0  2013-05-07  42.18  42.410  41.900  42.40   3524022  41.662857  41.933333   \n",
      "1  2013-05-08  42.40  42.950  42.300  42.94   2119765  41.874286  41.983333   \n",
      "2  2013-05-09  42.97  43.195  42.630  43.16   3159293  42.120000  42.072000   \n",
      "3  2013-05-10  43.12  43.850  43.040  43.63   4662252  42.451429  42.180667   \n",
      "4  2013-05-13  43.43  43.560  42.720  43.04   4260335  42.674286  42.260000   \n",
      "5  2013-05-14  42.98  44.060  42.882  43.97   6075845  43.020000  42.350667   \n",
      "6  2013-05-15  44.90  46.490  44.890  45.68  10289000  43.545714  42.539333   \n",
      "7  2013-05-16  45.43  45.840  44.970  44.99   4890962  43.915714  42.690000   \n",
      "8  2013-05-17  45.02  45.830  44.990  45.56   3247851  44.290000  42.974000   \n",
      "9  2013-05-20  45.48  47.450  45.390  46.34   5698804  44.744286  43.299333   \n",
      "\n",
      "   30_day_ma  daily_returns  ...  daily_returns_lag_5  daily_returns_lag_7  \\\n",
      "0  42.018333       0.009524  ...            -0.000482            -0.033466   \n",
      "1  42.055667       0.012736  ...            -0.003137             0.003874   \n",
      "2  42.091333       0.005123  ...             0.004115            -0.000482   \n",
      "3  42.146667       0.010890  ...             0.001688            -0.003137   \n",
      "4  42.217000      -0.013523  ...             0.010830             0.004115   \n",
      "5  42.327333       0.021608  ...             0.009524             0.001688   \n",
      "6  42.499333       0.038890  ...             0.012736             0.010830   \n",
      "7  42.618667      -0.015105  ...             0.005123             0.009524   \n",
      "8  42.752667       0.012669  ...             0.010890             0.012736   \n",
      "9  42.908667       0.017120  ...            -0.013523             0.005123   \n",
      "\n",
      "   daily_returns_lag_15  daily_returns_lag_30  daily_volatility_lag_1  \\\n",
      "0              0.008132             -0.002909                0.016187   \n",
      "1             -0.027656              0.016776                0.016249   \n",
      "2             -0.008533              0.006456                0.016132   \n",
      "3              0.004064             -0.002851                0.016118   \n",
      "4             -0.003571             -0.024780                0.016201   \n",
      "5              0.018160             -0.006597                0.015696   \n",
      "6              0.005632             -0.003443                0.016017   \n",
      "7             -0.002800              0.021964                0.017270   \n",
      "8             -0.033466              0.003139                0.017277   \n",
      "9              0.003874              0.002889                0.017369   \n",
      "\n",
      "   daily_volatility_lag_3  daily_volatility_lag_5  daily_volatility_lag_7  \\\n",
      "0                0.016785                0.017213                0.017317   \n",
      "1                0.016177                0.017067                0.017309   \n",
      "2                0.016187                0.016785                0.017213   \n",
      "3                0.016249                0.016177                0.017067   \n",
      "4                0.016132                0.016187                0.016785   \n",
      "5                0.016118                0.016249                0.016177   \n",
      "6                0.016201                0.016132                0.016187   \n",
      "7                0.015696                0.016118                0.016249   \n",
      "8                0.016017                0.016201                0.016132   \n",
      "9                0.017270                0.015696                0.016118   \n",
      "\n",
      "   daily_volatility_lag_15  daily_volatility_lag_30  \n",
      "0                 0.015512                 0.014528  \n",
      "1                 0.016143                 0.014885  \n",
      "2                 0.015994                 0.014960  \n",
      "3                 0.016020                 0.014934  \n",
      "4                 0.016008                 0.015500  \n",
      "5                 0.016352                 0.012400  \n",
      "6                 0.016362                 0.011862  \n",
      "7                 0.016289                 0.012236  \n",
      "8                 0.017317                 0.011968  \n",
      "9                 0.017309                 0.011956  \n",
      "\n",
      "[10 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# create data frame\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e54fe46-a479-468b-95eb-da85e1acc7e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date   open    high     low  close    volume   7_day_ma  15_day_ma  \\\n",
      "0 2013-05-07  42.18  42.410  41.900  42.40   3524022  41.662857  41.933333   \n",
      "1 2013-05-08  42.40  42.950  42.300  42.94   2119765  41.874286  41.983333   \n",
      "2 2013-05-09  42.97  43.195  42.630  43.16   3159293  42.120000  42.072000   \n",
      "3 2013-05-10  43.12  43.850  43.040  43.63   4662252  42.451429  42.180667   \n",
      "4 2013-05-13  43.43  43.560  42.720  43.04   4260335  42.674286  42.260000   \n",
      "5 2013-05-14  42.98  44.060  42.882  43.97   6075845  43.020000  42.350667   \n",
      "6 2013-05-15  44.90  46.490  44.890  45.68  10289000  43.545714  42.539333   \n",
      "7 2013-05-16  45.43  45.840  44.970  44.99   4890962  43.915714  42.690000   \n",
      "8 2013-05-17  45.02  45.830  44.990  45.56   3247851  44.290000  42.974000   \n",
      "9 2013-05-20  45.48  47.450  45.390  46.34   5698804  44.744286  43.299333   \n",
      "\n",
      "   30_day_ma  daily_returns  ...  daily_returns_lag_30  \\\n",
      "0  42.018333       0.009524  ...             -0.002909   \n",
      "1  42.055667       0.012736  ...              0.016776   \n",
      "2  42.091333       0.005123  ...              0.006456   \n",
      "3  42.146667       0.010890  ...             -0.002851   \n",
      "4  42.217000      -0.013523  ...             -0.024780   \n",
      "5  42.327333       0.021608  ...             -0.006597   \n",
      "6  42.499333       0.038890  ...             -0.003443   \n",
      "7  42.618667      -0.015105  ...              0.021964   \n",
      "8  42.752667       0.012669  ...              0.003139   \n",
      "9  42.908667       0.017120  ...              0.002889   \n",
      "\n",
      "   daily_volatility_lag_1  daily_volatility_lag_3  daily_volatility_lag_5  \\\n",
      "0                0.016187                0.016785                0.017213   \n",
      "1                0.016249                0.016177                0.017067   \n",
      "2                0.016132                0.016187                0.016785   \n",
      "3                0.016118                0.016249                0.016177   \n",
      "4                0.016201                0.016132                0.016187   \n",
      "5                0.015696                0.016118                0.016249   \n",
      "6                0.016017                0.016201                0.016132   \n",
      "7                0.017270                0.015696                0.016118   \n",
      "8                0.017277                0.016017                0.016201   \n",
      "9                0.017369                0.017270                0.015696   \n",
      "\n",
      "   daily_volatility_lag_7  daily_volatility_lag_15  daily_volatility_lag_30  \\\n",
      "0                0.017317                 0.015512                 0.014528   \n",
      "1                0.017309                 0.016143                 0.014885   \n",
      "2                0.017213                 0.015994                 0.014960   \n",
      "3                0.017067                 0.016020                 0.014934   \n",
      "4                0.016785                 0.016008                 0.015500   \n",
      "5                0.016177                 0.016352                 0.012400   \n",
      "6                0.016187                 0.016362                 0.011862   \n",
      "7                0.016249                 0.016289                 0.012236   \n",
      "8                0.016132                 0.017317                 0.011968   \n",
      "9                0.016118                 0.017309                 0.011956   \n",
      "\n",
      "   year  month  day  \n",
      "0  2013      5    7  \n",
      "1  2013      5    8  \n",
      "2  2013      5    9  \n",
      "3  2013      5   10  \n",
      "4  2013      5   13  \n",
      "5  2013      5   14  \n",
      "6  2013      5   15  \n",
      "7  2013      5   16  \n",
      "8  2013      5   17  \n",
      "9  2013      5   20  \n",
      "\n",
      "[10 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "# transform date to datetime, get year,month,day from date column\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d9158c-e788-4ad2-b72a-5059af903e21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['open_lag_1', 'open_lag_3', 'open_lag_5', 'open_lag_7', 'open_lag_15', 'open_lag_30', 'high_lag_1', 'high_lag_3', 'high_lag_5', 'high_lag_7', 'high_lag_15', 'high_lag_30', 'low_lag_1', 'low_lag_3', 'low_lag_5', 'low_lag_7', 'low_lag_15', 'low_lag_30', 'volume_lag_1', 'volume_lag_3', 'volume_lag_5', 'volume_lag_7', 'volume_lag_15', 'volume_lag_30', '7_day_ma_lag_1', '7_day_ma_lag_3', '7_day_ma_lag_5', '7_day_ma_lag_7', '7_day_ma_lag_15', '7_day_ma_lag_30', '15_day_ma_lag_1', '15_day_ma_lag_3', '15_day_ma_lag_5', '15_day_ma_lag_7', '15_day_ma_lag_15', '15_day_ma_lag_30', '30_day_ma_lag_1', '30_day_ma_lag_3', '30_day_ma_lag_5', '30_day_ma_lag_7', '30_day_ma_lag_15', '30_day_ma_lag_30', 'daily_returns_lag_1', 'daily_returns_lag_3', 'daily_returns_lag_5', 'daily_returns_lag_7', 'daily_returns_lag_15', 'daily_returns_lag_30', 'daily_volatility_lag_1', 'daily_volatility_lag_3', 'daily_volatility_lag_5', 'daily_volatility_lag_7', 'daily_volatility_lag_15', 'daily_volatility_lag_30', 'year', 'month', 'day']\n",
      "\n",
      "\n",
      "\n",
      "['open', 'high', 'low', 'volume', '7_day_ma', '15_day_ma', '30_day_ma', 'daily_returns', 'daily_volatility']\n"
     ]
    }
   ],
   "source": [
    "#define features, target vars\n",
    "#clist of lagged columns\n",
    "lag_columns = ['open', 'high', 'low', 'volume', '7_day_ma', '15_day_ma', '30_day_ma', 'daily_returns', 'daily_volatility']\n",
    "#a list of columns to exclude. This should be all the columns with data from a day d for which we are trying \n",
    "#to make predictions for (because we will not have access to this data in practice)\n",
    "exclude = [col for col in lag_columns if any(f'{col}_lag_' in c for c in df.columns)]\n",
    "#a list of the features to include. This is all columns that are not the date, target, or included\n",
    "#in our list of columns to exclude\n",
    "include = [col for col in df.columns if col not in ['date', 'close'] + exclude]\n",
    "print(include)\n",
    "print('\\n\\n')\n",
    "print(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28779f2-992a-4a73-b48b-cf9ffe11c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into features and our target variable\n",
    "features = df[include]\n",
    "target = df['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1842752f-8df7-4fa3-ae00-ce14caf673b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "scaler=MinMaxScaler()\n",
    "scaled_feat = scaler.fit_transform(features)\n",
    "\n",
    "#reshape for CONV1D\n",
    "X = scaled_feat.reshape((features.shape[0],features.shape[1],1))\n",
    "\n",
    "y = df['close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6f175e-8e97-4589-adae-c04cfc1d785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70405050-92b5-4b2b-9677-4f64996859fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 14:00:00.841576: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#initialize sequential model\n",
    "#this will be used to create a linear stack of layers\n",
    "model = Sequential() \n",
    "\n",
    "#add convolutional layer w/ 64 output filters\n",
    "#kernel size 3\n",
    "#using rectified linear unit for activation function\n",
    "#input_shape is shape of data given number of features with one data point per step\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X.shape[1],1)))\n",
    "\n",
    "#add LSTM layer w/ 50 neurons\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "\n",
    "#add layer to flatten input to 1-d array\n",
    "model.add(Flatten())\n",
    "\n",
    "#add connected NN layer\n",
    "#w/ 1 output neuron\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "#configure model for training\n",
    "#use Adam for optimizer\n",
    "#Use MSE for loss func\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edcd339a-df42-43ba-87fa-6e6c2bec6cef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14693/14693 [==============================] - 309s 21ms/step - loss: 370.1361\n",
      "Epoch 2/10\n",
      "14693/14693 [==============================] - 302s 21ms/step - loss: 32.2570\n",
      "Epoch 3/10\n",
      "14693/14693 [==============================] - 291s 20ms/step - loss: 27.8937\n",
      "Epoch 4/10\n",
      "14693/14693 [==============================] - 301s 20ms/step - loss: 22.3319\n",
      "Epoch 5/10\n",
      "14693/14693 [==============================] - 307s 21ms/step - loss: 19.3059\n",
      "Epoch 6/10\n",
      "14693/14693 [==============================] - 308s 21ms/step - loss: 16.6048\n",
      "Epoch 7/10\n",
      "14693/14693 [==============================] - 327s 22ms/step - loss: 14.8309\n",
      "Epoch 8/10\n",
      "14693/14693 [==============================] - 319s 22ms/step - loss: 13.5716\n",
      "Epoch 9/10\n",
      "14693/14693 [==============================] - 314s 21ms/step - loss: 13.0534\n",
      "Epoch 10/10\n",
      "14693/14693 [==============================] - 412s 28ms/step - loss: 17.2252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3acfd0a30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5611a92-37a9-4df1-bbe9-4061d9c5e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3674/3674 [==============================] - 38s 10ms/step - loss: 11.5320\n",
      "3674/3674 [==============================] - 37s 10ms/step\n",
      "Mean Squared Error: 11.532030729977805\n",
      "Mean Absolute Error: 1.9028174238558095\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "# For a more detailed evaluation, you can make predictions and compare them to the actual values\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics like MSE or MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
