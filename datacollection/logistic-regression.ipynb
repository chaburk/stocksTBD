{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d574e97c-0c85-4356-abf9-686cce088be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebb6640-72df-4882-a865-76036e308d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>positive</td>\n",
       "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f...\n",
       "5  positive  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...\n",
       "6  positive  For the last quarter of 2010 , Componenta 's n...\n",
       "7  positive  In the third quarter of 2010 , net sales incre...\n",
       "8  positive  Operating profit rose to EUR 13.1 mn from EUR ...\n",
       "9  positive  Operating profit totalled EUR 21.1 mn , up fro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the data\n",
    "df = pd.read_csv('kaggle-training/all-data.csv', header=None,encoding='latin-1')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef236a4c-5831-4901-8f21-c8fdda451a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697e480f-ca2c-440e-862e-b2d827d54584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment                                           headline\n",
      "0   neutral  According to Gran , the company has no plans t...\n",
      "1   neutral  Technopolis plans to develop in stages an area...\n",
      "2  negative  The international electronic industry company ...\n",
      "3  positive  With the new production plant the company woul...\n",
      "4  positive  According to the company 's updated strategy f...\n"
     ]
    }
   ],
   "source": [
    "#df.columns = ['y','x']\n",
    "#rename column names\n",
    "df.columns = ['sentiment','headline']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ddd90b-c8f5-4e0a-91fe-b92e5eaeb2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row count:  4846\n"
     ]
    }
   ],
   "source": [
    "print('row count: ', df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381c7f6b-400c-4b07-9dd5-38a530cf446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set, test_set = train_test_split(df,test_size=0.2)\n",
    "#print(\"training set: \", train_set.shape)\n",
    "#print(\"testing set: \", test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c520d185-231e-48c4-b330-4e3f82c30700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing sets\n",
    "X = df['headline']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65508a79-e9d0-4007-9bf1-4153a5b71108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3876,)\n",
      "(970,)\n",
      "(3876,)\n",
      "(970,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d12bb5-7359-4c97-a81b-5aa2abca4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract feautures from data using term frequency-inverse document frequency (TD-IDF) vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english',max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "499cf83f-7cc6-465c-99e3-123be2c8c571",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2670)\t0.27091155179146137\n",
      "  (0, 892)\t0.1535385593823909\n",
      "  (0, 1893)\t0.29079430361892006\n",
      "  (0, 4395)\t0.3177735167393831\n",
      "  (0, 4856)\t0.24592881612880818\n",
      "  (0, 2727)\t0.27091155179146137\n",
      "  (0, 2711)\t0.27959691847289214\n",
      "  (0, 1689)\t0.2526177053524291\n",
      "  (0, 2977)\t0.20826775886910454\n",
      "  (0, 1531)\t0.2402226017989342\n",
      "  (0, 4102)\t0.20182547729393766\n",
      "  (0, 4007)\t0.1629946993096093\n",
      "  (0, 1364)\t0.2402226017989342\n",
      "  (0, 2669)\t0.18207489121987233\n",
      "  (0, 3436)\t0.23225143454958694\n",
      "  (0, 4935)\t0.26069960603912656\n",
      "  (0, 2531)\t0.24592881612880818\n",
      "  (1, 1430)\t0.4877202376201351\n",
      "  (1, 2151)\t0.5635331077302123\n",
      "  (1, 3891)\t0.23453057639456223\n",
      "  (1, 2341)\t0.46145757129399256\n",
      "  (1, 4780)\t0.42025197791226643\n",
      "  (2, 4516)\t0.15319320327413008\n",
      "  (2, 1123)\t0.1927442149645805\n",
      "  (2, 2741)\t0.19008552696582642\n",
      "  :\t:\n",
      "  (3874, 313)\t0.4650762956105486\n",
      "  (3874, 1685)\t0.41180586929068447\n",
      "  (3874, 2129)\t0.4771367201537468\n",
      "  (3874, 3772)\t0.4235475702833861\n",
      "  (3874, 2654)\t0.2753061123841253\n",
      "  (3874, 1599)\t0.22680166681042982\n",
      "  (3874, 148)\t0.2825517999992722\n",
      "  (3875, 3538)\t0.2920905423194422\n",
      "  (3875, 4507)\t0.2920905423194422\n",
      "  (3875, 329)\t0.2920905423194422\n",
      "  (3875, 118)\t0.2920905423194422\n",
      "  (3875, 996)\t0.26846515865644316\n",
      "  (3875, 2809)\t0.26846515865644316\n",
      "  (3875, 486)\t0.23723410023983185\n",
      "  (3875, 509)\t0.23398552673622533\n",
      "  (3875, 3959)\t0.23398552673622533\n",
      "  (3875, 1104)\t0.1605005666251167\n",
      "  (3875, 3991)\t0.26085948390283087\n",
      "  (3875, 1375)\t0.22576570520762254\n",
      "  (3875, 4308)\t0.24483977499344414\n",
      "  (3875, 162)\t0.19357446431443578\n",
      "  (3875, 193)\t0.19552266448665082\n",
      "  (3875, 45)\t0.18237765816022147\n",
      "  (3875, 4024)\t0.15087501086561517\n",
      "  (3875, 1793)\t0.11116235786704633\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d991ed0-2836-4224-9b01-2cd7cf95dab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, multi_class='multinomial')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model = LogisticRegression(multi_class='multinomial',solver='lbfgs', max_iter = 10000)\n",
    "model.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cb5bf59-c416-4409-9606-cec271b3b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dda11203-7636-4bd0-bf1c-77ce8ed0ecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.10%\n",
      "Confusion Matrix:\n",
      "[[ 46  66  26]\n",
      " [  6 523  28]\n",
      " [  9 155 111]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.33      0.46       138\n",
      "     neutral       0.70      0.94      0.80       557\n",
      "    positive       0.67      0.40      0.50       275\n",
      "\n",
      "    accuracy                           0.70       970\n",
      "   macro avg       0.71      0.56      0.59       970\n",
      "weighted avg       0.70      0.70      0.67       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(matrix)\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8a5f377-24bc-482e-a91f-94350d0b80ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral']\n"
     ]
    }
   ],
   "source": [
    "#make new predictions\n",
    "new_headline = [\"Apple to close down\"]\n",
    "new_headline_vec = vectorizer.transform(new_headline)\n",
    "prediction = model.predict(new_headline_vec)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d816eca-6d48-4b19-a212-5dcf204fbd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral']\n"
     ]
    }
   ],
   "source": [
    "#make new predictions\n",
    "new_headline = [\"YouTube surpasses Netflix as top video platform for teens: Survey\"]\n",
    "new_headline_vec = vectorizer.transform(new_headline)\n",
    "prediction = model.predict(new_headline_vec)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6193aa64-cf34-4e7d-af7e-7fc3a6ecd2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     2879\n",
      "positive    1363\n",
      "negative     604\n",
      "Name: sentiment, dtype: int64\n",
      "neutral     59.409823\n",
      "positive    28.126290\n",
      "negative    12.463888\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = df['sentiment'].value_counts()\n",
    "print(class_distribution)\n",
    "\n",
    "#view as percent\n",
    "class_distribution_percentage = df['sentiment'].value_counts(normalize=True) * 100\n",
    "print(class_distribution_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0fd895e-9253-4e3b-8906-e2e40d5b18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "X = df['headline']  # News headlines\n",
    "y = df['sentiment']  # Sentiment\n",
    "\n",
    "# Split data into training and testing sets (let's assume an 80-20 split for demonstration)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Convert X_train and y_train back to a dataframe for easy manipulation\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Perform undersampling on df_train\n",
    "df_train_negative = df_train[df_train['sentiment'] == 'negative']\n",
    "df_train_positive = df_train[df_train['sentiment'] == 'positive']\n",
    "df_train_neutral = df_train[df_train['sentiment'] == 'neutral']\n",
    "\n",
    "# Get the count of the minority class\n",
    "minority_count = len(df_train_negative)\n",
    "\n",
    "df_train_positive_downsampled = df_train_positive.sample(minority_count, random_state=42)\n",
    "df_train_neutral_downsampled = df_train_neutral.sample(minority_count, random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "df_train_downsampled = pd.concat([df_train_negative, df_train_positive_downsampled, df_train_neutral_downsampled])\n",
    "df_train_downsampled = df_train_downsampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Extract X_train and y_train from df_train_downsampled for further processing\n",
    "X_train_downsampled = df_train_downsampled['headline']\n",
    "y_train_downsampled = df_train_downsampled['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40c0e32f-663d-4eac-b50c-46cbfa079189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Feature Extraction\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train_downsampled)\n",
    "X_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14a20d5c-e3ba-4192-869c-057364736828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2. Model Training\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_vec, y_train_downsampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea541641-2825-4978-9b76-6eab5d585d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.73      0.58       121\n",
      "     neutral       0.78      0.73      0.75       576\n",
      "    positive       0.55      0.50      0.52       273\n",
      "\n",
      "    accuracy                           0.66       970\n",
      "   macro avg       0.60      0.65      0.62       970\n",
      "weighted avg       0.68      0.66      0.67       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Evaluation\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1f7565c-0720-492e-90a5-510a7af9331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "#make new predictions\n",
    "new_headline = [\"Apple to lay off 1000 workers\"]\n",
    "new_headline_vec = vectorizer.transform(new_headline)\n",
    "prediction = model.predict(new_headline_vec)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0e72b-9344-4df6-8070-aeb7f11a9d98",
   "metadata": {},
   "source": [
    "The logistic regression model appears to consistently say that all headlines, whether positive, negative, or neutral, are neutral which is not the case. I am unsure yet if this is due to a problem with the dataset used for training (as my scraper is still running) or if it is the model itself. I will further experiment with other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
