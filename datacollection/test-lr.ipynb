{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900967f2-9584-4b9a-816c-7726fc1e22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from datetime import datetime\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db40f83-17c5-4578-8431-ff56fcbb4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to fetch data for specified company\n",
    "def fetch_data_for_company(stock_symbol, start_date, end_date):\n",
    "    df = web.DataReader(stock_symbol, 'yahoo', start_date, end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7e93de-1a3c-4bba-96b9-6cbe32405aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to preprocess data\n",
    "#employs preprocessing techniques seen in\n",
    "#process-data.ipynb\n",
    "#and linear-regression.ipynb\n",
    "def preprocess_data(df):\n",
    "    # Add your preprocessing steps here\n",
    "    #drop Adj Close column\n",
    "    df = df.drop('Adj Close', axis=1)\n",
    "\n",
    "    #make column names lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    #calculate moving averages\n",
    "    df['7_day_ma'] = df['close'].rolling(window=7).mean()\n",
    "    df['15_day_ma'] = df['close'].rolling(window=15).mean()\n",
    "    df['30_day_ma'] = df['close'].rolling(window=30).mean()\n",
    "    \n",
    "    #calculate daily returns\n",
    "    df['daily_returns'] = df['close'].pct_change()\n",
    "    \n",
    "    #create column for daily volatility over window_size time frame\n",
    "    window_size = 30  # change as needed\n",
    "    df['daily_volatility'] = df['daily_returns'].rolling(window=window_size).std().reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "    #Convert the 'date' column to datetime objects this is necessary to ensure dates are sorted properly\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    \n",
    "    # columns to create lag for\n",
    "    lag_columns = ['open', 'high', 'low', 'volume', '7_day_ma', '15_day_ma', '30_day_ma', 'daily_returns', 'daily_volatility']\n",
    "    # create lag features\n",
    "    for col in lag_columns: #for every column\n",
    "        for n in [1, 3, 5, 7, 15, 30]:  # for every lag features\n",
    "            column_name = f'{col}_lag_{n}'  # Name for the new lagged column\n",
    "            df[column_name] = df[col].shift(n)  # Create the lagged column\n",
    "            \n",
    "    # drop NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    \n",
    "    #a list of columns to exclude. This should be all the columns with data from a day d for which we are trying \n",
    "    #to make predictions for (because we will not have access to this data in practice)\n",
    "    exclude = [col for col in lag_columns if any(f'{col}_lag_' in c for c in df.columns)]\n",
    "    #a list of the features to include. This is all columns that are not the date, target, or included\n",
    "    #in our list of columns to exclude\n",
    "    features = [col for col in df.columns if col not in ['date', 'close'] + exclude]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f7a93c-05aa-4445-a7d1-99d62478a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model\n",
    "model = load('lr-model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63213e6-7dc9-4cdc-bf81-bd513ed634b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of companies\n",
    "with open('../news-scraping/s&pCompanies.txt', 'r') as file:\n",
    "    companies = file.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b277d4-1ca7-4aff-96e2-704af04da3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start and end date for data being pulled\n",
    "start_date = datetime(2023, 6, 1)\n",
    "end_date = datetime(2023, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6efc241-ac00-4c14-937e-18cd4ff18f75",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (798369847.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [7]\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"MSE: {mse}, R2: {r2}\\n\")\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for company in companies:# for each company\n",
    "    try:\n",
    "        company_data = fetch_data_for_company(company, start_date, end_date)#get company data\n",
    "        processed_data = preprocess_data(company_data) #preprocess data\n",
    "        predictions = model.predict(processed_data) #make predictions\n",
    "        \n",
    "        # Calculate the difference between actual and predicted prices\n",
    "        difference = company_data['Close'] - predictions\n",
    "        difference_sign = difference.apply(lambda x: '+' if x > 0 else '-')\n",
    "\n",
    "        #Calculate MSE and R2\n",
    "        mse = mean_squared_error(company_data['Close'], predictions)\n",
    "        r2 = r2_score(company_data['Close'], predictions)\n",
    "\n",
    "        #output results\n",
    "        print(f\"Company: {company}\")\n",
    "        print(f\"Actual Prices: \\n{company_data['Close']}\")\n",
    "        print(f\"Predicted Prices: \\n{predictions}\")\n",
    "        print(f\"Difference: \\n{difference_sign}{abs(difference)}\")\n",
    "        print(f\"MSE: {mse}, R2: {r2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801ab11-77c5-4223-a93a-ee7b5e2e06e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424aab44-4332-4224-a61a-b0c64d80a666",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime(\u001b[38;5;241m2020\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m31\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# web.DataReader('FB', 'yahoo', start='2020-01-01', end='2019-10-09')\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mweb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas_datareader/data.py:370\u001b[0m, in \u001b[0;36mDataReader\u001b[0;34m(name, data_source, start, end, retry_count, pause, session, api_key)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myahoo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mYahooDailyReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43msymbols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43madjust_price\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpause\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m data_source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miex\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IEXDailyReader(\n\u001b[1;32m    383\u001b[0m         symbols\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    384\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m    391\u001b[0m     )\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas_datareader/base.py:253\u001b[0m, in \u001b[0;36m_DailyBaseReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# If a single symbol, (e.g., 'GOOG')\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbols, (string_types, \u001b[38;5;28mint\u001b[39m)):\n\u001b[0;32m--> 253\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_one_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymbols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Or multiple symbols, (e.g., ['GOOG', 'AAPL', 'MSFT'])\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbols, DataFrame):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas_datareader/yahoo/daily.py:153\u001b[0m, in \u001b[0;36mYahooDailyReader._read_one_data\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     j \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(re\u001b[38;5;241m.\u001b[39msearch(ptrn, resp\u001b[38;5;241m.\u001b[39mtext, re\u001b[38;5;241m.\u001b[39mDOTALL)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 153\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mj\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdispatcher\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHistoricalPriceStore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data fetched for symbol \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "stocks = 'FB'\n",
    "data_source = 'yahoo'\n",
    "start = datetime(2020,1,1)\n",
    "end = datetime(2020,12,31)\n",
    "# web.DataReader('FB', 'yahoo', start='2020-01-01', end='2019-10-09')\n",
    "df = web.DataReader(stocks, data_source, start, end)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bde35b4-2d46-43af-a3cb-b9e9ca17261f",
   "metadata": {},
   "source": [
    "There appears to be an issue pulling new data and the format "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
